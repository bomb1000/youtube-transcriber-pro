const express = require('express');
const cors = require('cors');
const path = require('path');
const fs = require('fs-extra');
const { spawn } = require('child_process');
const OpenAI = require('openai');
const axios = require('axios');
const apiLogger = require('./api-logger');
require('dotenv').config();

const app = express();
const PORT = process.env.PORT || 3000;

// Default API Keys from environment variables
const DEFAULT_API_KEYS = {
    gemini: process.env.GEMINI_API_KEY || '',
    openai: process.env.OPENAI_API_KEY || '',
    assemblyai: process.env.ASSEMBLYAI_API_KEY || ''
};

// Middleware
app.use(cors());
app.use(express.json());
app.use(express.static(path.join(__dirname)));

// Ensure temp directory exists
const TEMP_DIR = path.join(__dirname, 'temp');
fs.ensureDirSync(TEMP_DIR);

// ===== API to get default keys status =====
app.get('/api/config', (req, res) => {
    res.json({
        hasDefaultKeys: {
            gemini: !!DEFAULT_API_KEYS.gemini,
            openai: !!DEFAULT_API_KEYS.openai,
            assemblyai: !!DEFAULT_API_KEYS.assemblyai
        }
    });
});

// ===== Routes =====

// Health check
app.get('/api/health', (req, res) => {
    res.json({ status: 'ok', message: 'YouTube Transcriber Pro API is running' });
});

// Download audio from YouTube using yt-dlp
app.post('/api/download', async (req, res) => {
    const { url } = req.body;

    if (!url) {
        return res.status(400).json({ error: 'Missing YouTube URL' });
    }

    try {
        const videoId = extractVideoId(url);
        if (!videoId) {
            return res.status(400).json({ error: 'Invalid YouTube URL' });
        }

        const audioPath = path.join(TEMP_DIR, `${videoId}.webm`);

        // Check if already downloaded and has content
        if (await fs.pathExists(audioPath)) {
            const stats = await fs.stat(audioPath);
            if (stats.size > 0) {
                console.log(`Audio already exists: ${audioPath} (${(stats.size / 1024 / 1024).toFixed(2)} MB)`);
                return res.json({
                    success: true,
                    videoId,
                    audioPath,
                    message: 'Audio already downloaded'
                });
            } else {
                // File is empty, delete it and re-download
                await fs.remove(audioPath);
            }
        }

        console.log(`Downloading audio for video: ${videoId} using yt-dlp`);

        // Cross-platform yt-dlp path detection
        const isWindows = process.platform === 'win32';
        let ytdlpPath = 'yt-dlp'; // Default: assume it's in PATH (Linux/Railway)
        let ffmpegPath = '';

        if (isWindows) {
            // Windows: try WinGet Links path first
            const wingetLinks = process.env.LOCALAPPDATA
                ? path.join(process.env.LOCALAPPDATA, 'Microsoft', 'WinGet', 'Links')
                : '';
            if (wingetLinks && fs.existsSync(path.join(wingetLinks, 'yt-dlp.exe'))) {
                ytdlpPath = path.join(wingetLinks, 'yt-dlp.exe');
                ffmpegPath = wingetLinks;
            }
        }

        const ytdlpArgs = [
            '-x',                           // Extract audio only
            '--audio-format', 'opus',       // Convert to opus (webm container)
            '--audio-quality', '0',         // Best quality
            '-o', audioPath.replace('.webm', '.%(ext)s'),  // Output path
            '--no-playlist',                // Don't download playlist
            '--no-warnings',                // Suppress warnings
        ];

        // Add ffmpeg location if available (Windows)
        if (ffmpegPath) {
            ytdlpArgs.push('--ffmpeg-location', ffmpegPath);
        }

        ytdlpArgs.push(url);

        await new Promise((resolve, reject) => {
            const ytdlp = spawn(ytdlpPath, ytdlpArgs);

            let stderr = '';

            ytdlp.stdout.on('data', (data) => {
                console.log(`yt-dlp: ${data}`);
            });

            ytdlp.stderr.on('data', (data) => {
                stderr += data.toString();
                console.error(`yt-dlp stderr: ${data}`);
            });

            ytdlp.on('close', (code) => {
                if (code === 0) {
                    resolve();
                } else {
                    reject(new Error(`yt-dlp exited with code ${code}: ${stderr}`));
                }
            });

            ytdlp.on('error', (err) => {
                reject(new Error(`Failed to start yt-dlp: ${err.message}`));
            });
        });

        // Find the downloaded file (might have different extension)
        const files = await fs.readdir(TEMP_DIR);
        const downloadedFile = files.find(f => f.startsWith(videoId));

        if (!downloadedFile) {
            throw new Error('Download completed but file not found');
        }

        const actualPath = path.join(TEMP_DIR, downloadedFile);
        const stats = await fs.stat(actualPath);

        // Rename to .webm if needed
        if (actualPath !== audioPath) {
            await fs.rename(actualPath, audioPath);
        }

        console.log(`Audio downloaded successfully: ${audioPath} (${(stats.size / 1024 / 1024).toFixed(2)} MB)`);

        res.json({
            success: true,
            videoId,
            audioPath,
            message: 'Audio downloaded successfully'
        });

    } catch (error) {
        console.error('Download error:', error);
        res.status(500).json({ error: `ä¸‹è¼‰å¤±æ•—: ${error.message}` });
    }
});

// Transcribe audio with OpenAI
app.post('/api/transcribe/openai', async (req, res) => {
    const { videoId, apiKey: userApiKey } = req.body;
    const apiKey = userApiKey || DEFAULT_API_KEYS.openai;

    if (!videoId) {
        return res.status(400).json({ error: 'Missing videoId' });
    }
    if (!apiKey) {
        return res.status(400).json({ error: 'Missing apiKey - no default key configured' });
    }

    try {
        const audioPath = path.join(TEMP_DIR, `${videoId}.webm`);

        if (!await fs.pathExists(audioPath)) {
            return res.status(404).json({ error: 'æ‰¾ä¸åˆ°éŸ³è¨Šæª”æ¡ˆï¼Œè«‹é‡æ–°ä¸‹è¼‰ã€‚' });
        }

        // Check file size (OpenAI Whisper limit is 25MB)
        const stats = await fs.stat(audioPath);
        const fileSizeMB = stats.size / (1024 * 1024);
        console.log(`Audio file size: ${fileSizeMB.toFixed(2)} MB`);

        if (fileSizeMB > 25) {
            return res.status(400).json({
                error: `éŸ³è¨Šæª”æ¡ˆå¤ªå¤§ (${fileSizeMB.toFixed(2)} MB)ã€‚\n\nOpenAI Whisper API é™åˆ¶æœ€å¤§ 25MBã€‚\n\nå»ºè­°ï¼š\n1. å˜—è©¦ä½¿ç”¨è¼ƒçŸ­çš„å½±ç‰‡\n2. æ”¹ç”¨ AssemblyAIï¼ˆç„¡å¤§å°é™åˆ¶ï¼‰`
            });
        }

        console.log('Creating OpenAI client...');
        const openai = new OpenAI({
            apiKey,
            timeout: 300000, // 5 minutes timeout
            maxRetries: 3
        });

        console.log('Sending to OpenAI Whisper API...');
        const audioFile = fs.createReadStream(audioPath);

        const transcription = await openai.audio.transcriptions.create({
            file: audioFile,
            model: 'whisper-1',
            response_format: 'verbose_json',
            timestamp_granularities: ['segment']
        });

        console.log('Transcription completed successfully');

        // Process segments with simple speaker detection based on pauses
        const segments = processSegmentsWithSpeakers(transcription.segments);

        res.json({
            success: true,
            transcript: segments,
            language: transcription.language,
            duration: transcription.duration
        });

    } catch (error) {
        console.error('OpenAI transcription error:', error);

        let errorMessage = error.message;

        // Provide more helpful error messages
        if (error.code === 'ECONNRESET' || error.message.includes('Connection error')) {
            errorMessage = `OpenAI API é€£ç·šå¤±æ•—\n\nå¯èƒ½åŸå› ï¼š\n1. ç¶²è·¯é€£ç·šä¸ç©©å®š\n2. éŸ³è¨Šæª”æ¡ˆå¤ªå¤§å°è‡´ä¸Šå‚³è¶…æ™‚\n3. API Key ç„¡æ•ˆ\n\nå»ºè­°ï¼š\n1. æª¢æŸ¥ç¶²è·¯é€£ç·š\n2. å˜—è©¦è¼ƒçŸ­çš„å½±ç‰‡\n3. ç¢ºèª API Key æ˜¯å¦æ­£ç¢º`;
        } else if (error.message.includes('Invalid API Key') || error.status === 401) {
            errorMessage = `OpenAI API Key ç„¡æ•ˆ\n\nè«‹ç¢ºèªæ‚¨çš„ API Key æ˜¯å¦æ­£ç¢ºã€‚\n\nå–å¾— API Keyï¼šhttps://platform.openai.com/api-keys`;
        } else if (error.status === 429) {
            errorMessage = `OpenAI API è«‹æ±‚æ¬¡æ•¸è¶…éé™åˆ¶\n\nè«‹ç¨å¾Œå†è©¦ï¼Œæˆ–å‡ç´šæ‚¨çš„ OpenAI æ–¹æ¡ˆã€‚`;
        }

        res.status(500).json({ error: errorMessage });
    }
});

// Transcribe with AssemblyAI (supports speaker diarization natively)
app.post('/api/transcribe/assemblyai', async (req, res) => {
    const { videoId, apiKey: userApiKey } = req.body;
    const apiKey = userApiKey || DEFAULT_API_KEYS.assemblyai;

    if (!videoId) {
        return res.status(400).json({ error: 'Missing videoId' });
    }
    if (!apiKey) {
        return res.status(400).json({ error: 'Missing apiKey - no default key configured' });
    }

    try {
        const audioPath = path.join(TEMP_DIR, `${videoId}.webm`);

        if (!await fs.pathExists(audioPath)) {
            return res.status(404).json({ error: 'Audio file not found' });
        }

        // Step 1: Upload audio to AssemblyAI
        console.log('Uploading to AssemblyAI...');
        const uploadResponse = await axios.post(
            'https://api.assemblyai.com/v2/upload',
            fs.createReadStream(audioPath),
            {
                headers: {
                    'authorization': apiKey,
                    'content-type': 'application/octet-stream'
                },
                maxContentLength: Infinity,
                maxBodyLength: Infinity
            }
        );

        const uploadUrl = uploadResponse.data.upload_url;
        console.log('Upload complete, starting transcription...');

        // Step 2: Start transcription with speaker diarization
        const transcriptResponse = await axios.post(
            'https://api.assemblyai.com/v2/transcript',
            {
                audio_url: uploadUrl,
                speaker_labels: true,
                language_code: 'zh'
            },
            {
                headers: {
                    'authorization': apiKey,
                    'content-type': 'application/json'
                }
            }
        );

        const transcriptId = transcriptResponse.data.id;
        console.log(`Transcription started: ${transcriptId}`);

        // Step 3: Poll for completion
        let transcript;
        while (true) {
            const pollResponse = await axios.get(
                `https://api.assemblyai.com/v2/transcript/${transcriptId}`,
                { headers: { 'authorization': apiKey } }
            );

            console.log(`Status: ${pollResponse.data.status}`);

            if (pollResponse.data.status === 'completed') {
                transcript = pollResponse.data;
                break;
            } else if (pollResponse.data.status === 'error') {
                throw new Error(pollResponse.data.error);
            }

            await new Promise(r => setTimeout(r, 3000));
        }

        // Process utterances with speaker labels
        const segments = (transcript.utterances || []).map((utt, idx) => ({
            id: idx + 1,
            speaker: `è¬›è€… ${utt.speaker}`,
            start: utt.start / 1000,
            end: utt.end / 1000,
            text: utt.text
        }));

        res.json({
            success: true,
            transcript: segments
        });

    } catch (error) {
        console.error('AssemblyAI error:', error);
        res.status(500).json({ error: error.message });
    }
});

// Transcribe with Gemini
app.post('/api/transcribe/gemini', async (req, res) => {
    const { videoId, apiKey: userApiKey } = req.body;
    const apiKey = userApiKey || DEFAULT_API_KEYS.gemini;

    if (!videoId) {
        return res.status(400).json({ error: 'Missing videoId' });
    }
    if (!apiKey) {
        return res.status(400).json({ error: 'Missing apiKey - no default key configured' });
    }

    try {
        const audioPath = path.join(TEMP_DIR, `${videoId}.webm`);

        if (!await fs.pathExists(audioPath)) {
            return res.status(404).json({ error: 'Audio file not found' });
        }

        // Check file size
        const stats = await fs.stat(audioPath);
        const fileSizeMB = stats.size / (1024 * 1024);
        console.log(`Audio file size: ${fileSizeMB.toFixed(2)} MB`);

        let fileUri;

        // For files > 20MB, use File API
        if (fileSizeMB > 20) {
            console.log('File is large, uploading via Gemini File API...');

            // Step 1: Start resumable upload
            const startUploadResponse = await axios.post(
                `https://generativelanguage.googleapis.com/upload/v1beta/files?key=${apiKey}`,
                {
                    file: {
                        display_name: `audio_${videoId}`
                    }
                },
                {
                    headers: {
                        'X-Goog-Upload-Protocol': 'resumable',
                        'X-Goog-Upload-Command': 'start',
                        'X-Goog-Upload-Header-Content-Length': stats.size,
                        'X-Goog-Upload-Header-Content-Type': 'audio/webm',
                        'Content-Type': 'application/json'
                    }
                }
            );

            const uploadUrl = startUploadResponse.headers['x-goog-upload-url'];
            console.log('Got upload URL, uploading file...');

            // Step 2: Upload the file
            const audioBuffer = await fs.readFile(audioPath);
            const uploadResponse = await axios.put(
                uploadUrl,
                audioBuffer,
                {
                    headers: {
                        'Content-Length': stats.size,
                        'X-Goog-Upload-Offset': '0',
                        'X-Goog-Upload-Command': 'upload, finalize'
                    },
                    maxBodyLength: Infinity,
                    maxContentLength: Infinity,
                    timeout: 600000 // 10 minutes for upload
                }
            );

            fileUri = uploadResponse.data.file.uri;
            console.log('File uploaded successfully:', fileUri);

            // Step 3: Wait for file processing
            let fileState = 'PROCESSING';
            let attempts = 0;
            const maxAttempts = 60;

            while (fileState === 'PROCESSING' && attempts < maxAttempts) {
                await new Promise(r => setTimeout(r, 5000));

                const statusResponse = await axios.get(
                    `https://generativelanguage.googleapis.com/v1beta/${uploadResponse.data.file.name}?key=${apiKey}`
                );

                fileState = statusResponse.data.state;
                console.log(`File processing status: ${fileState}`);
                attempts++;
            }

            if (fileState !== 'ACTIVE') {
                throw new Error('File processing timeout or failed');
            }

            // Step 4: Generate content using file URI
            console.log('Sending transcription request...');
            const transcriptionResponse = await axios.post(
                `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${apiKey}`,
                {
                    contents: [{
                        parts: [
                            {
                                file_data: {
                                    mime_type: 'audio/webm',
                                    file_uri: fileUri
                                }
                            },
                            {
                                text: `è«‹å°‡é€™æ®µéŸ³è¨Šè½‰éŒ„æˆé€å­—ç¨¿ï¼Œä¸¦è­˜åˆ¥ä¸åŒçš„è¬›è€…ã€‚
è«‹ä½¿ç”¨ä»¥ä¸‹ JSON æ ¼å¼å›è¦†ï¼š
{
  "segments": [
    {"speaker": "è¬›è€… A", "start": 0.0, "end": 5.0, "text": "å…§å®¹..."}
  ]
}
åªå›è¦† JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚`
                            }
                        ]
                    }]
                },
                {
                    headers: { 'Content-Type': 'application/json' },
                    timeout: 600000
                }
            );

            const textContent = transcriptionResponse.data.candidates[0].content.parts[0].text;
            const jsonMatch = textContent.match(/\{[\s\S]*\}/);

            if (!jsonMatch) {
                throw new Error('Failed to parse Gemini response');
            }

            const parsed = JSON.parse(jsonMatch[0]);
            const segments = parsed.segments.map((seg, idx) => ({
                id: idx + 1,
                ...seg
            }));

            res.json({
                success: true,
                transcript: segments
            });

        } else {
            // For smaller files, use inline base64
            console.log('File is small, using inline base64...');
            const audioBuffer = await fs.readFile(audioPath);
            const audioBase64 = audioBuffer.toString('base64');

            const response = await axios.post(
                `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${apiKey}`,
                {
                    contents: [{
                        parts: [
                            {
                                inline_data: {
                                    mime_type: 'audio/webm',
                                    data: audioBase64
                                }
                            },
                            {
                                text: `è«‹å°‡é€™æ®µéŸ³è¨Šè½‰éŒ„æˆé€å­—ç¨¿ï¼Œä¸¦è­˜åˆ¥ä¸åŒçš„è¬›è€…ã€‚
è«‹ä½¿ç”¨ä»¥ä¸‹ JSON æ ¼å¼å›è¦†ï¼š
{
  "segments": [
    {"speaker": "è¬›è€… A", "start": 0.0, "end": 5.0, "text": "å…§å®¹..."}
  ]
}
åªå›è¦† JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚`
                            }
                        ]
                    }]
                },
                {
                    headers: { 'Content-Type': 'application/json' },
                    timeout: 300000
                }
            );

            const textContent = response.data.candidates[0].content.parts[0].text;
            const jsonMatch = textContent.match(/\{[\s\S]*\}/);

            if (!jsonMatch) {
                throw new Error('Failed to parse Gemini response');
            }

            const parsed = JSON.parse(jsonMatch[0]);
            const segments = parsed.segments.map((seg, idx) => ({
                id: idx + 1,
                ...seg
            }));

            res.json({
                success: true,
                transcript: segments
            });
        }

    } catch (error) {
        console.error('Gemini error:', error);

        let errorMessage = error.message;

        if (error.response?.status === 429 || error.message.includes('429')) {
            errorMessage = `Gemini API è«‹æ±‚æ¬¡æ•¸è¶…éé™åˆ¶ (429)\n\nå¯èƒ½åŸå› ï¼š\n1. å…è²»é¡åº¦å·²ç”¨å®Œ\n2. çŸ­æ™‚é–“å…§ç™¼é€å¤ªå¤šè«‹æ±‚\n\nè§£æ±ºæ–¹æ¡ˆï¼š\n1. ç­‰å¾…å¹¾åˆ†é˜å¾Œå†è©¦\n2. åˆ° Google AI Studio æª¢æŸ¥ä½ çš„é¡åº¦\n\né¡åº¦æŸ¥è©¢ï¼šhttps://aistudio.google.com/`;
        } else if (error.response?.status === 400) {
            errorMessage = `Gemini API è«‹æ±‚æ ¼å¼éŒ¯èª¤\n\nå¯èƒ½æ˜¯éŸ³è¨Šæ ¼å¼ä¸æ”¯æ´ï¼Œè«‹å˜—è©¦å…¶ä»–å½±ç‰‡ã€‚`;
        } else if (error.response?.status === 403) {
            errorMessage = `Gemini API Key ç„¡æ•ˆæˆ–ç„¡æ¬Šé™\n\nè«‹ç¢ºèªæ‚¨çš„ API Key æ˜¯å¦æ­£ç¢ºã€‚\n\nå–å¾— API Keyï¼šhttps://aistudio.google.com/apikey`;
        }

        res.status(500).json({ error: errorMessage });
    }
});

// AI Correction
app.post('/api/correct', async (req, res) => {
    const { transcript, provider, apiKey: userApiKey } = req.body;
    const apiKey = userApiKey || (provider === 'gemini' ? DEFAULT_API_KEYS.gemini : DEFAULT_API_KEYS.openai);

    if (!transcript) {
        return res.status(400).json({ error: 'Missing transcript' });
    }
    if (!apiKey) {
        return res.status(400).json({ error: 'Missing apiKey - no default key configured' });
    }

    try {
        const prompt = `è«‹ä¿®æ­£ä»¥ä¸‹é€å­—ç¨¿ä¸­çš„éŒ¯èª¤ï¼ŒåŒ…æ‹¬ï¼š
1. ä¿®æ­£æ˜é¡¯çš„èªéŸ³è¾¨è­˜éŒ¯èª¤
2. æ·»åŠ é©ç•¶çš„æ¨™é»ç¬¦è™Ÿ
3. ä¿®æ­£éŒ¯åˆ¥å­—
4. ä¿æŒåŸæ„ä¸è®Š

è«‹ä¿æŒç›¸åŒçš„ JSON æ ¼å¼å›è¦†ï¼š
${JSON.stringify(transcript, null, 2)}

åªå›è¦†ä¿®æ­£å¾Œçš„ JSON é™£åˆ—ï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚`;

        let correctedTranscript;

        if (provider === 'openai') {
            const openai = new OpenAI({ apiKey });
            const completion = await openai.chat.completions.create({
                model: 'gpt-4o',
                messages: [{ role: 'user', content: prompt }],
                temperature: 0.3
            });

            const response = completion.choices[0].message.content;
            const jsonMatch = response.match(/\[[\s\S]*\]/);
            correctedTranscript = JSON.parse(jsonMatch[0]);

        } else if (provider === 'gemini') {
            const response = await axios.post(
                `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${apiKey}`,
                {
                    contents: [{ parts: [{ text: prompt }] }]
                }
            );

            const textContent = response.data.candidates[0].content.parts[0].text;
            const jsonMatch = textContent.match(/\[[\s\S]*\]/);
            correctedTranscript = JSON.parse(jsonMatch[0]);
        }

        res.json({
            success: true,
            transcript: correctedTranscript
        });

    } catch (error) {
        console.error('Correction error:', error);
        res.status(500).json({ error: error.message });
    }
});

// AI Refine with Custom Prompt
app.post('/api/refine', async (req, res) => {
    const { transcript, prompt, provider, apiKey: userApiKey, context } = req.body;
    const apiKey = userApiKey || (provider === 'gemini' ? DEFAULT_API_KEYS.gemini : DEFAULT_API_KEYS.openai);

    if (!transcript || !prompt) {
        return res.status(400).json({ error: 'Missing transcript or prompt' });
    }
    if (!apiKey) {
        return res.status(400).json({ error: 'Missing apiKey - no default key configured' });
    }

    const startTime = Date.now();
    let model = '';

    try {
        const systemPrompt = `ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„é€å­—ç¨¿ç·¨è¼¯åŠ©æ‰‹ã€‚è«‹æ ¹æ“šç”¨æˆ¶çš„æŒ‡ç¤ºä¿®æ”¹ä»¥ä¸‹é€å­—ç¨¿ã€‚

${context ? `å½±ç‰‡ç›¸é—œèƒŒæ™¯ï¼š${context}\n\n` : ''}ç”¨æˆ¶æŒ‡ç¤ºï¼š${prompt}

é€å­—ç¨¿ï¼š
${JSON.stringify(transcript, null, 2)}

è«‹æŒ‰ç…§ç›¸åŒçš„ JSON æ ¼å¼å›è¦†ä¿®æ”¹å¾Œçš„é€å­—ç¨¿ï¼Œä¸¦åœ¨æœ€å¾Œé™„ä¸Šä¸€å€‹ "changes" æ¬„ä½èªªæ˜ä½ åšäº†å“ªäº›ä¿®æ”¹ã€‚
æ ¼å¼ï¼š
{
  "transcript": [...ä¿®æ”¹å¾Œçš„é€å­—ç¨¿...],
  "changes": "1. ä¿®æ”¹é …ç›®ä¸€\n2. ä¿®æ”¹é …ç›®äºŒ..."
}
åªå›è¦† JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚`;

        let result;

        if (provider === 'openai') {
            model = 'gpt-4o';
            const openai = new OpenAI({ apiKey });
            const completion = await openai.chat.completions.create({
                model: model,
                messages: [{ role: 'user', content: systemPrompt }],
                temperature: 0.3
            });

            const response = completion.choices[0].message.content;
            const jsonMatch = response.match(/\{[\s\S]*\}/);
            result = JSON.parse(jsonMatch[0]);

        } else if (provider === 'gemini') {
            model = 'gemini-2.0-flash';
            const response = await axios.post(
                `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${apiKey}`,
                {
                    contents: [{ parts: [{ text: systemPrompt }] }]
                }
            );

            const textContent = response.data.candidates[0].content.parts[0].text;
            const jsonMatch = textContent.match(/\{[\s\S]*\}/);
            result = JSON.parse(jsonMatch[0]);
        }

        const duration = Date.now() - startTime;

        // Log the API call
        apiLogger.log({
            provider,
            model,
            action: 'refine',
            duration,
            success: true
        });

        res.json({
            success: true,
            transcript: result.transcript,
            changes: result.changes || 'ç„¡å…·é«”ä¿®æ”¹èªªæ˜'
        });

    } catch (error) {
        const duration = Date.now() - startTime;
        apiLogger.log({
            provider,
            model,
            action: 'refine',
            duration,
            success: false,
            error: error.message
        });

        console.error('Refine error:', error);
        res.status(500).json({ error: error.message });
    }
});

// Get API Logs
app.get('/api/logs', (req, res) => {
    res.json({
        logs: apiLogger.getLogs(),
        stats: apiLogger.getStats()
    });
});

// ===== Helper Functions =====

function extractVideoId(url) {
    const patterns = [
        /(?:youtube\.com\/watch\?v=|youtu\.be\/|youtube\.com\/embed\/)([^&\n?#]+)/
    ];

    for (const pattern of patterns) {
        const match = url.match(pattern);
        if (match) return match[1];
    }
    return null;
}

// Simple speaker detection based on pauses between segments
function processSegmentsWithSpeakers(segments) {
    if (!segments || segments.length === 0) return [];

    let currentSpeaker = 0;
    const speakerLetters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ';

    return segments.map((seg, idx) => {
        // Switch speaker if there's a significant pause (> 2 seconds)
        if (idx > 0) {
            const pause = seg.start - segments[idx - 1].end;
            if (pause > 2) {
                currentSpeaker = (currentSpeaker + 1) % speakerLetters.length;
            }
        }

        return {
            id: idx + 1,
            speaker: `è¬›è€… ${speakerLetters[currentSpeaker]}`,
            start: seg.start,
            end: seg.end,
            text: seg.text.trim()
        };
    });
}

// ===== Start Server =====
app.listen(PORT, () => {
    console.log(`
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                                                       â•‘
    â•‘   ğŸ¬ YouTube Transcriber Pro                          â•‘
    â•‘   Server running at http://localhost:${PORT}             â•‘
    â•‘                                                       â•‘
    â•‘   âœ… ä½¿ç”¨ yt-dlp ä¸‹è¼‰ YouTube éŸ³è¨Š                    â•‘
    â•‘                                                       â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    `);
});
